{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e393f49-19e3-4ef7-bed5-d7ea1fae5014",
   "metadata": {},
   "source": [
    "# Shap values \n",
    "\n",
    "## Idea central\n",
    "\n",
    "En cada permutaci√≥n posible del orden de las variables, se calcula la contribuci√≥n marginal de cada feature en ese orden. Luego, se promedian esas contribuciones para obtener su valor de Shapley.\n",
    "\n",
    "## ¬øQu√© es una contribuci√≥n marginal?\n",
    "\n",
    "La contribuci√≥n marginal de una variable es cu√°nto cambia la predicci√≥n del modelo cuando se agrega esa variable a un conjunto de variables ya conocidas.\n",
    "\n",
    "Ejemplo con la permutaci√≥n $[x_2, x_1, x_3]$:\n",
    "\n",
    "1. Partimos del baseline del modelo, sin variables: f(‚àÖ)\n",
    "2. Agregamos $x_2$: contribuci√≥n de $x_2 = f({x2}) - f(‚àÖ)$\n",
    "3. Luego agregamos $x_1$: contribuci√≥n de $x1 = f({x_2, x_1}) - f({x_2})$\n",
    "4. Finalmente agregamos $x_3$: contribuci√≥n de $x_3 = f({x_2, x_1, x_3}) - f({x_2, x_1})$\n",
    "\n",
    "## Repetir para todas las permutaciones posibles\n",
    "\n",
    "Con 3 variables existen 3! = 6 permutaciones:\n",
    "\n",
    "1. $[x_1, x_2, x_3]$  \n",
    "2. $[x_1, x_3, x_2]$  \n",
    "3. $[x_2, x_1, x_3]$  \n",
    "4. $[x_2, x_3, x_1]$  \n",
    "5. $[x_3, x_1, x_2]$  \n",
    "6. $[x_3, x_2, x_1]$\n",
    "\n",
    "En cada una de estas permutaciones, calculamos las contribuciones marginales de x1, x2 y x3 en el momento exacto en que se agregan.\n",
    "\n",
    "## üìä C√°lculo final\n",
    "\n",
    "Para cada variable, su valor de Shapley se obtiene como el promedio de sus contribuciones marginales a lo largo de todas las permutaciones:\n",
    "\n",
    "SHAP x1 = promedio de las contribuciones de x1  \n",
    "SHAP x2 = promedio de las contribuciones de x2  \n",
    "SHAP x3 = promedio de las contribuciones de x3\n",
    "\n",
    "## ‚úÖ Predicci√≥n explicada\n",
    "\n",
    "La predicci√≥n del modelo para una observaci√≥n se descompone como:\n",
    "\n",
    "$f(x_1, x_2, x_3) = f(‚àÖ) + \\text{SHAP} x_1 + \\text{SHAP} x_2 + \\text{SHAP} x_3$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- `f(‚àÖ)` es la predicci√≥n promedio del dataset (baseline)\n",
    "- `SHAP xi` es la contribuci√≥n de la variable `xi` para esa observaci√≥n espec√≠fica\n",
    "\n",
    "Esta es una explicaci√≥n completa, justa y basada en teor√≠a de juegos del porqu√© el modelo predijo lo que predijo para esa observaci√≥n espec√≠fica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0776a640-5ee7-49fd-b184-70a6e0f4c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dataset simple con 3 variables\n",
    "X3 = pd.DataFrame({\n",
    "    'x1': [1, 2, 3, 4],\n",
    "    'x2': [10, 20, 30, 40],\n",
    "    'x3': [100, 200, 300, 400]\n",
    "})\n",
    "y3 = 3 * X3['x1'] + 2 * X3['x2'] + 0.5 * X3['x3'] + 5\n",
    "\n",
    "# Entrenamos modelo\n",
    "model = DecisionTreeRegressor(max_depth=3, random_state=0)\n",
    "model.fit(X3, y3)\n",
    "\n",
    "# Observaci√≥n que queremos explicar\n",
    "x_exp = pd.DataFrame({'x1': [2], 'x2': [20], 'x3': [200]})\n",
    "\n",
    "# Baseline (f(‚àÖ)): promedio del modelo con datos originales\n",
    "f_empty = np.mean(model.predict(X3))\n",
    "\n",
    "# Permutaci√≥n a analizar: [x2, x1, x3]\n",
    "# Paso 1: f({}) ‚Üí baseline\n",
    "\n",
    "# Paso 2: f({x2}) ‚Üí fijamos x2 = 20, sampleamos x1 y x3\n",
    "\n",
    "# Paso 3: f({x2, x1}) ‚Üí fijamos x2 = 20, x1 = 2, sampleamos x3\n",
    "\n",
    "# Paso 4: f({x2, x1, x3}) ‚Üí fijamos x1, x2, x3 (predicci√≥n completa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d75850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b621d063-64dc-4207-991b-c027cc0f357a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutaci√≥n: [x2, x1, x3]\n",
      "f(‚àÖ) = 187.5\n",
      "f({x2}) = 132.75 ‚Üí Œîx2 = -54.75\n",
      "f({x2, x1}) = 132.75 ‚Üí Œîx1 = 0.0\n",
      "f({x2, x1, x3}) = 78.0 ‚Üí Œîx3 = -54.75\n"
     ]
    }
   ],
   "source": [
    "# Mostramos resultados de esta permutaci√≥n\n",
    "print(\"Permutaci√≥n: [x2, x1, x3]\")\n",
    "print(f\"f(‚àÖ) = {round(f_empty, 2)}\")\n",
    "print(f\"f({{x2}}) = {round(f_x2, 2)} ‚Üí Œîx2 = {round(delta_x2, 2)}\")\n",
    "print(f\"f({{x2, x1}}) = {round(f_x2_x1, 2)} ‚Üí Œîx1 = {round(delta_x1, 2)}\")\n",
    "print(f\"f({{x2, x1, x3}}) = {round(f_x2_x1_x3, 2)} ‚Üí Œîx3 = {round(delta_x3, 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102745ea-123c-46ed-ba30-7203cf202749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "344d89c8-6076-4c01-9ea6-99515b121739",
   "metadata": {},
   "source": [
    "### C√≥digo generalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6e22600-7254-4e3c-8e3b-aed157f17bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x1': -9.12,\n",
       " 'x2': -45.62,\n",
       " 'x3': 18.25,\n",
       " 'baseline': 187.5,\n",
       " 'f(x1,x2,x3)': 151.0,\n",
       " 'suma total': 151.01}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "# Creamos un nuevo dataset con tres variables\n",
    "X3 = pd.DataFrame({\n",
    "    'x1': [1, 2, 3, 4],\n",
    "    'x2': [10, 20, 30, 40],\n",
    "    'x3': [100, 200, 300, 400]\n",
    "})\n",
    "y3 = 3 * X3['x1'] + 2 * X3['x2'] + 0.5 * X3['x3'] + 5\n",
    "\n",
    "# Entrenamos un √°rbol de decisi√≥n\n",
    "model3 = DecisionTreeRegressor(max_depth=3, random_state=0)\n",
    "model3.fit(X3, y3)\n",
    "\n",
    "# Observaci√≥n a explicar\n",
    "x_exp = pd.DataFrame({'x1': [2], 'x2': [20], 'x3': [200]})\n",
    "f_full = model3.predict(x_exp)[0]\n",
    "\n",
    "# Baseline (sin ninguna variable)\n",
    "f_base = np.mean(model3.predict(X3))\n",
    "\n",
    "# Definimos todas las permutaciones posibles de orden de entrada\n",
    "features = ['x1', 'x2', 'x3']\n",
    "perms = list(permutations(features))\n",
    "\n",
    "# Calculamos contribuci√≥n marginal para cada variable en cada orden\n",
    "shap_values = {'x1': [], 'x2': [], 'x3': []}\n",
    "\n",
    "for perm in perms:\n",
    "    known = []\n",
    "    for i, feat in enumerate(perm):\n",
    "        # fijamos las variables conocidas hasta ahora\n",
    "        X_temp = X3.copy()\n",
    "        for k in known:\n",
    "            X_temp[k] = x_exp[k].iloc[0]\n",
    "        f_prev = np.mean(model3.predict(X_temp))\n",
    "        known.append(feat)\n",
    "        for k in known:\n",
    "            X_temp[k] = x_exp[k].iloc[0]\n",
    "        f_curr = np.mean(model3.predict(X_temp))\n",
    "\n",
    "        # contribuci√≥n marginal de esta variable\n",
    "        delta = f_curr - f_prev\n",
    "        shap_values[feat].append(delta)\n",
    "\n",
    "# Promediamos las contribuciones marginales para cada variable\n",
    "phi = {k: round(np.mean(v), 2) for k, v in shap_values.items()}\n",
    "phi['baseline'] = round(f_base, 2)\n",
    "phi['f(x1,x2,x3)'] = round(f_full, 2)\n",
    "phi['suma total'] = round(f_base + sum(phi[k] for k in features), 2)\n",
    "phi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221d4a4b-ba1a-492f-91e2-f4992bb4af49",
   "metadata": {},
   "source": [
    "# Generalizaci√≥n te√≥rica de los valores de Shapley\n",
    "\n",
    "Los valores de Shapley provienen de la teor√≠a de juegos cooperativos y se utilizan para asignar de manera justa la \"recompensa\" total (en este caso, la predicci√≥n de un modelo) entre todos los jugadores (features), de acuerdo con su contribuci√≥n individual al resultado.\n",
    "\n",
    "\n",
    "## F√≥rmula general\n",
    "\n",
    "Sea:\n",
    "\n",
    "- $N = \\{1, 2, ..., n\\}$ el conjunto total de variables (features)\n",
    "- $i \\in N$ una variable espec√≠fica\n",
    "- $S \\subseteq N \\setminus \\{i\\}$ un subconjunto de variables que **no contiene** a $i$\n",
    "- $f(S)$ la predicci√≥n del modelo usando solo las variables en $S$\n",
    "- $f(S \\cup \\{i\\})$ la predicci√≥n del modelo al a√±adir $i$ al conjunto $S$\n",
    "\n",
    "Entonces, el valor de Shapley para la variable $i$ es:\n",
    "\n",
    "$$\n",
    "\\phi_i = \\sum_{S \\subseteq N \\setminus \\{i\\}} \\frac{|S|! \\cdot (n - |S| - 1)!}{n!} \\cdot \\left[ f(S \\cup \\{i\\}) - f(S) \\right]\n",
    "$$\n",
    "\n",
    "\n",
    "## Interpretaci√≥n de cada componente\n",
    "\n",
    "- $\\phi_i$ = valor de Shapley de la variable $i$\n",
    "- $f(S \\cup \\{i\\}) - f(S)$ = contribuci√≥n marginal de $i$ al conjunto $S$\n",
    "- $\\frac{|S|! \\cdot (n - |S| - 1)!}{n!}$ = peso que representa la **proporci√≥n de permutaciones** donde $i$ es agregada **despu√©s de $S$ y antes del resto**\n",
    "\n",
    "Este peso asegura que todas las posiciones posibles de $i$ en el orden de las variables son consideradas de forma justa.\n",
    "\n",
    "---\n",
    "\n",
    "## Descomposici√≥n de la predicci√≥n\n",
    "\n",
    "La predicci√≥n del modelo para una observaci√≥n $x$ se puede expresar como:\n",
    "\n",
    "$$\n",
    "f(x) = f(\\emptyset) + \\sum_{i=1}^{n} \\phi_i\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- $f(\\emptyset)$ es el valor base o baseline (por ejemplo, la media de todas las predicciones del dataset)\n",
    "- Cada $\\phi_i$ representa la contribuci√≥n justa de la variable $x_i$ a la predicci√≥n $f(x)$\n",
    "\n",
    "\n",
    "## Propiedades deseables de los valores de Shapley\n",
    "\n",
    "1. **Eficiencia:**  \n",
    "   La suma de los valores de Shapley es igual a la diferencia entre la predicci√≥n completa y el baseline:\n",
    "   $$\n",
    "   \\sum_i \\phi_i = f(x) - f(\\emptyset)\n",
    "   $$\n",
    "\n",
    "2. **Simetr√≠a:**  \n",
    "   Si dos variables hacen la misma contribuci√≥n en todos los contextos, reciben el mismo valor de Shapley.\n",
    "\n",
    "3. **Ausencia:**  \n",
    "   Si una variable no cambia nunca la predicci√≥n, su Shapley value es 0.\n",
    "\n",
    "4. **Aditividad:**  \n",
    "   Si se combinan dos modelos, los Shapley values se suman.\n",
    "\n",
    "\n",
    "## Conclusi√≥n\n",
    "\n",
    "El valor de Shapley de una variable es el **promedio ponderado de sus contribuciones marginales** al modelo, considerando **todas las combinaciones posibles** en las que puede ser agregada.  \n",
    "Es una forma matem√°tica rigurosa y justa de entender c√≥mo cada variable contribuye a una predicci√≥n individual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75cd159-ea04-4b5b-9bad-11aff103105c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
