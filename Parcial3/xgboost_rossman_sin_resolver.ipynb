{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aff1812-3c90-492c-91a5-fc4bdd9e127c",
   "metadata": {},
   "source": [
    "# Rossman dataset \n",
    "\n",
    "Fuente xgboost: https://xgboost.readthedocs.io/en/release_3.0.0/\n",
    "\n",
    "https://cloud.google.com/python/docs/reference/bigframes/latest/bigframes.ml.ensemble.XGBRegressor\n",
    "\n",
    "Correr esto:\n",
    "\n",
    "!pip install xgboost==1.7.6 scikit-learn==1.2.2\n",
    "\n",
    "https://www.kaggle.com/competitions/rossmann-store-sales/data\n",
    "\n",
    "- Id - an Id that represents a (Store, Date) duple within the test set\n",
    "- Store - a unique Id for each store\n",
    "- Sales - the turnover for any given day (this is what you are predicting)\n",
    "- Customers - the number of customers on a given day\n",
    "- Open - an indicator for whether the store was open: 0 = closed, 1 = open\n",
    "- StateHoliday - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None\n",
    "- SchoolHoliday - indicates if the (Store, Date) was affected by the closure of public schools\n",
    "- StoreType - differentiates between 4 different store models: a, b, c, d\n",
    "- Assortment - describes an assortment level: a = basic, b = extra, c = extended\n",
    "- CompetitionDistance - distance in meters to the nearest competitor store\n",
    "- CompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened\n",
    "- Promo - indicates whether a store is running a promo on that day\n",
    "- Promo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating\n",
    "- Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2\n",
    "- PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e87506d-9256-411c-a66b-569f18f3a90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/z6bgw1fj4vng6rs97g1chhz00000gn/T/ipykernel_83435/3565455745.py:8: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train = pd.read_csv('rossman.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carga de datos\n",
    "train = pd.read_csv('train.csv')\n",
    "stores = pd.read_csv('store.csv')\n",
    "\n",
    "# Merge de ambos datasets\n",
    "\n",
    "# Convertir la columna de fecha\n",
    "\n",
    "# Ordenar por fecha para evitar leakage\n",
    "\n",
    "# Filtrar solo tiendas abiertas\n",
    "\n",
    "# Variables temporales útiles, mes y dia del mes\n",
    "\n",
    "# df['week_of_year'] = df['Date'].dt.isocalendar().week.astype(int)\n",
    "\n",
    "# Eliminar columnas que no usaremos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6419bd1a-a1de-4ea4-a3a6-cb45879dd8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 90% de datos\n",
    "\n",
    "# Obten X_train, y_train, X_test, y_test\n",
    "\n",
    "# Codificar variables categóricas (después del split para evitar leakage)\n",
    "\n",
    "# Alinear columnas en test con train\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f17de00f-5abb-4b72-b05a-b110c9d4ea01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 0.5352\n"
     ]
    }
   ],
   "source": [
    "# Xgboost\n",
    "\n",
    "# Fit\n",
    "\n",
    "# Predicción y evaluación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bda8db0-89cf-40aa-a587-e5313864e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una regresion lineal para ver que tan bien da\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Calcular medias solo en train\n",
    "\n",
    "\n",
    "# Aplicar a ambos\n",
    "\n",
    "# Entrenar modelo\n",
    "\n",
    "# Predecir\n",
    "\n",
    "# Evaluar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3425b0f8-8557-4015-b5ae-4ba162554a7d",
   "metadata": {},
   "source": [
    "### Tuneando xgboost\n",
    "\n",
    "- n_estimators: número total de árboles a entrenar. Si usas early_stopping_rounds, puedes poner un número alto sin preocuparte por overfitting.\n",
    "\n",
    "- max_depth: profundidad máxima de cada árbol. Profundidades mayores capturan más complejidad, pero pueden sobreajustar.\n",
    "\n",
    "- learning_rate: qué tan rápido aprende el modelo. Valores más bajos requieren más árboles (n_estimators más alto), pero suelen generalizar mejor.\n",
    "\n",
    "- tree_method: método para construir árboles:\n",
    "\n",
    "    'exact': busca el mejor split evaluando todos los valores.\n",
    "    \n",
    "    'hist': agrupa en bins (default moderno), mucho más rápido.\n",
    "    \n",
    "    'gpu_hist': como 'hist' pero usando GPU (⚡ si tienes una buena GPU).\n",
    "\n",
    "- subsample: fracción de los datos usados en cada árbol (filas). Ayuda a reducir overfitting. Ej: 0.8 usa el 80% de los datos en cada iteración.\n",
    "\n",
    "- colsample_bytree (¡ojo con el nombre!): fracción de columnas seleccionadas aleatoriamente para cada árbol. También ayuda contra el overfitting.\n",
    "\n",
    "- early_stopping_rounds: si la métrica en el conjunto de validación no mejora durante N iteraciones, se detiene el entrenamiento (requiere eval_set).\n",
    "\n",
    "- eval_metric: métrica usada para evaluar el desempeño durante entrenamiento (ej. 'rmse', 'mae', 'logloss', 'auc'). Es la que define si se activa early_stopping.\n",
    "\n",
    "- gamma: mínima ganancia necesaria para hacer un split adicional. Ayuda a regular complejidad.\n",
    "\n",
    "- reg_lambda: regularización L2 (Ridge). Útil para evitar sobreajuste.\n",
    "\n",
    "- reg_alpha: regularización L1 (Lasso). Puede hacer pruning de features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f13826d-1e77-4e32-b2c4-a901b01e4488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Crea el modelo\n",
    "\n",
    "# Haz fit, usa early stopping, verboso y evalset [(X_train, y_train), (X_test, y_test)]\n",
    "\n",
    "# Extraer resultados después del fit, model.evals_result()\n",
    "\n",
    "# Predicción y métricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bb279ff-0b0f-4aa2-ba42-21de7e5b81f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafica ambos errores \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51c5eae6-c00f-4bd5-b7ef-92e9496632fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibracion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146cf21f-db4c-4dc1-82ec-411d91753c22",
   "metadata": {},
   "source": [
    "### Feature importances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e707f361-c35d-4ba5-9f8d-2480cdced075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41143e7f-8aa8-4f3f-93ac-b0a81e397140",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "for feature in importancias.features:\n",
    "    PartialDependenceDisplay.from_estimator(model, X_test, [feature])\n",
    "    plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a760af68-c41e-447d-a72c-6aaceb45a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial dependence plot \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5919bcd7-db86-473c-b051-8b9009d0a3d4",
   "metadata": {},
   "source": [
    "# Feature importance\n",
    "\n",
    "### Gain \n",
    "Gain es que tanto disminuye la función de perdida, en promedio al usar cada feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60a8076a-4c1d-411d-bd31-77aa7491a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "# Grafica la importancia, por importance_type y el max_num_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b83d524-4b5a-4b77-8c9d-b9366cdaa85c",
   "metadata": {},
   "source": [
    "### Weight\n",
    "Weighr es el porcentaje de veces que se uso esa variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c08201-9b81-47ff-a8cc-e250840576c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd6b14-6ff4-4d4e-a628-b574b99784d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1022884b-e946-4976-9b04-b97f2802bcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
