{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d323cad6-0afa-4c28-9ce0-07c970efdb6b",
   "metadata": {},
   "source": [
    "# Examen – Modelos de Ensamble: Árboles y Boosting\n",
    "\n",
    "**Instrucciones**: Justifica cada respuesta de manera clara. Usa fórmulas donde aplique y sé específico en tus argumentos.\n",
    "\n",
    "---\n",
    "\n",
    "## Sección I: Árboles de decisión (15 puntos)\n",
    "\n",
    "### 1. (5 pts)  \n",
    "Explica cómo se construye un árbol y qué criterio usa para decidir los splits. Explica tanto para el caso de clasificación como de regresión.\n",
    "\n",
    "Un árbol de decisión es un modelo de predicción, el cual utiliza distinos niveles de clasificación de datos con base en cierto valor (umbral). Divide los datos en grupos (ramas) que sobrepasan o no ese umbral. El modelo de regresión utiliza todas las varibles y splits posibles, donde finalmente aplica el tipo de split con mayor reducción de varianza, con base en el error cuadrático medio. De manera similar a la regresión, el calsificador utiliza todas las variables y umbrales posibles, eligiendo en este caso el umbral que maximice la pureza, con base en Gini o entropía.\n",
    "\n",
    "### 2. (5 pts)  \n",
    "Da un ejemplo de sobreajuste en un árbol de decisión. Explica cómo se podría evitar sin necesidad de usar ensambles.\n",
    "\n",
    "El ejemlo más básico de sobre ajuste en un árbol es si la profundidad del árbol es mucha, ya que finalmente se estaría creando una nueva rama para cada escenario posible, lo que equivale a la memorización de datos.\n",
    "\n",
    "### 3. (5 pts)  \n",
    "Si te fijas, en clase nunca hicimos escalamiento (`StandardScaler`). ¿Por qué los árboles no lo necesitan?\n",
    "\n",
    "No lo necesita, ya que no compara a todos los datos simultaneamente, sino que en cada nodo u hoja toma una variable base con cual toma la decisión de dividir los datos en ramas. Ya que en cada hoja se estan filtrando los datos únicamente por una única variable no es necesario escalar.\n",
    "\n",
    "---\n",
    "\n",
    "## Sección II: Random Forest (20 puntos)\n",
    "\n",
    "### 4. (10 pts)  \n",
    "Explica cómo funciona un Random Forest. ¿En qué se basa? ¿Por qué es una buena idea?\n",
    "\n",
    "Un random forest está basado en Bootstrap. El algoritmo realiza este resampleo de datos con boostrap muchas veces, y con cada uno de ellos realiza un árbol de decisión. Finalmente promedia la predicción de todos los diferentes árboles y toma ese valor como predicción del modelo de RF.\n",
    "\n",
    "### 5. (10 pts)  \n",
    "Menciona dos ventajas y dos desventajas del Random Forest comparado con un solo árbol. Sé específico, no generalices.\n",
    "\n",
    "Ventajas:\n",
    "- Al hacer bootstrap se limita el overfitting que se puede llegar a crear, porque en cada árbol se trabaja con diferentes datos de un mismo dataset y el resultado es el promedio de todo.\n",
    "- Podría verse como una especie de reductor de varianza, ya que por el mismo bootsrap habría casos en los que no considere outliers, o que tome menos de estos datos en cuanta, mostrando un mejor ajuste.\n",
    "\n",
    "Desventajas:\n",
    "- Ya que literalmente el Random Forest está compuesto de cientos de árboles, presenta un costo computacional mucho más elevado, sin contar el proceso de bootstrap que igualmente es costoso, computacionalmente hablando.\n",
    "- Es menos interpretable. Ya que el resultado final es un promedio de cientos de árboles, no se puede interpretar puntualmente cuales fueron las variables usadas por hoja, o el umbral utilizado para la filtración de datos, mientras que en un único árbos esto si es visible.\n",
    "\n",
    "---\n",
    "\n",
    "## Sección III: Gradient Boosting (25 puntos)\n",
    "\n",
    "### 6. (10 pts)  \n",
    "Explica, paso a paso, cómo funciona el algoritmo de **Gradient Boosting**. Incluye el concepto de residuales y cómo se minimiza la pérdida en cada iteración.\n",
    "\n",
    "Es un método secuencial que combina modelos débiles (como árboles) para formar un modelo fuerte. Este corrige los errores del modelo anterior en cada iteración. Comienza con una predicción inicial, y calcula los residuales de la misma (error de la predicción frente a datos reales). Con base en estos residuales se entrena un nuevo árbol, enfocado en mejorar en las áreas en donde más equivocación hubo. Se genera una nueva predicción con este árbol y se suma al modelo que ya se tenía de modo que este sea un poco mejor. Que tanto mejora el modelo depende del learning rate que se defina como hiperparámetro. A partir de este momento se repite iterativamente el modelo hasta que converger y haber encontrado el mejor resultado posible.\n",
    "\n",
    "### 7. (15 pts)  \n",
    "¿Cuál es la diferencia entre Gradient Boosting y Random Forest en términos de cómo combinan los árboles? \n",
    "\n",
    "La diferencia está en que Random Forest genera muchos árboles y al final promedia las predicciones de todos, mientras que Gradient Boosting comeinza con un modelo inicial e iterativamente agrega factores de nuevos árboles que permiten que el modelo mejore. Se podría decir que RF tiene muchos árboles, mientras que GB tiene máximo 2 de manera simultanea, los cuales junta para tener uno mejor.\n",
    "\n",
    "---\n",
    "\n",
    "## Sección IV: XGBoost (20 puntos)\n",
    "\n",
    "### 8. (10 pts)  \n",
    "Explica cómo XGBoost optimiza el proceso de boosting usando una expansión de Taylor de segundo orden.\n",
    "\n",
    "La funcion de pérdida es complica, por lo que mejor se opta por usar la expansión de taylos de segundo orden, ya que esta es fácil de optimizar, resultando en un modelo más sencillo, que si se tratara de optimizar la función de pérdida original. Ya que se utiliza la expansión y no la función original se dice que XGBoost se aproxima al error.\n",
    "\n",
    "### 9. (5 pts)  \n",
    "¿Qué es el *similarity score*? ¿Qué es el *output value*? ¿De dónde salen estas fórmulas y cuál es su interpretación?\n",
    "\n",
    "El output value es la optimización del término $w_j$ es cual es agregado a la función de pérdida como un regularizador. \n",
    "\n",
    "$$\\text{Output value} = w_j^* = -\\frac{G_j}{H_j + \\lambda}$$\n",
    "\n",
    "Su interpretación es la de la penalización que está recibiendo el modelo por hoja. \n",
    "\n",
    "Por otro lado el similarity score es la mejora que hay en cada una de las hojas, con base en el output value.\n",
    "\n",
    "$$\\text{Similarity Score} = \\frac{G_j^2}{H_j + \\lambda}$$\n",
    "\n",
    "Su interpretación es literalmente esa, la mejora que hay en cada una de las hojas por haber utilizado el penalizador óptimo.\n",
    "\n",
    "### 10. (5 pts)  \n",
    "XGBoost y otros modelos de gradient boosting permiten evaluar la importancia de las variables con diferentes métricas: `weight` y `gain`. Explica qué representa cada una. ¿Cuál crees que es más útil para interpretar un modelo y por qué?\n",
    "\n",
    "La metrica de importancia *weight* indica el número de veces que una variable fue utilizada en las diferentes hojas del modelo. Naturalmente la variable que más se haya utilizado se considera importante pues decisiva para la partición de ramas del modelo.\n",
    "\n",
    "*Gain* por otro lado muestra la mejora que hubo cada vez que se utilizo la variable. Es decir, por cada vez que se utilizo la variable tal en cada una de las hojas, el ajuse del modelo mejoro en tanta medida.\n",
    "\n",
    "Creo que la útilidad de interpretabilidad de ambas depende de los gustos de cada persona, ya que ambas son importantes, sin embargo, en lo persona, considero que gain es una mejor métrica, ya que muestra la mejora que hubo en el modelo por utilización y a fin de cuentas lo que se busca es encontrar el mejor modelo posible. \n",
    "\n",
    "---\n",
    "\n",
    "## Sección V: LightGBM y CatBoost (15 puntos)\n",
    "\n",
    "### 10. (5 pts)  \n",
    "Explica qué es **histogram-based splitting** y cómo lo implementa LightGBM para ganar velocidad.\n",
    "\n",
    "Histogram-based splitting es una técnica en donde los vlores continuos del dataset se agrupan en bins, para que el algoritmo no tenga que clacula el corto óptimo de todos los datos, sino que calcula el corte óptimo entre bins. Otra ventaja de esta técnica es que trabaja con el ínidce de los bins, es decir con int's, lo cual es naturalmente más rápido que trabajar con float's.\n",
    "\n",
    "### 11. (5 pts)  \n",
    "¿Qué problema específico resuelve CatBoost respecto al manejo de variables categóricas? ¿Cómo lo hace?\n",
    "\n",
    "La ventaja que presenta CatBoost es que no necesita un encoding manual para la variables categoricas, ya que utiliza una forma especial de target encoding regularizado, diseñado especialmente para evitar overfitting y data leakage.\n",
    "\n",
    "### 12. (5 pts)  \n",
    "Compara LightGBM y CatBoost: ¿cuándo usarías uno sobre el otro? Sé claro y justifica en base a tipo de datos, velocidad o precisión.\n",
    "\n",
    "El uso principal de LightGBM sería en el caso en el que el dataset cuente con muchas variables numéricas y este sea además muy largo. Por su separación en bins sería el adecuado, ya que ahorraría mucho tiempo en generar predicciones.\n",
    "\n",
    "Por otra parte CatBoost sería usado si se tuviera una gran cantidad de variables categóricas, para aprovechar la codificación nativa que tiene para este tipo de datos.\n",
    "\n",
    "## Sección VI: Power Analysis (5 puntos)\n",
    "\n",
    "### 13. (5 pts)  \n",
    "¿Qué es un *power analysis* y para qué sirve? ¿En qué contexto lo hemos usado en clase y por qué es importante antes de correr un experimento?\n",
    "\n",
    "El análisis de poder es utilizado principalemnte para ver la cantidad de personas (tamaño de muestra) necesario para considerar como válido un cambio en alguna estadística. De igualmanera, ayuda para determinar la magnitud significativa del cambio que esté analizando. \n",
    "\n",
    "El ejemplo más claro en el que se utilice esto es en el AB testing, pues es necesario calcular el tamaño de muestra necesario para aplicar la prueba y con eso se determina la magnitud de cambio que se espera en la efecto que se está analizando. \n",
    "\n",
    "Es útil hacer esto antes de correr un experimento, ya que dice la significancia de la prueba que se está haciendo. Si una prueba no es significativa no se pueden validar sus resultados, porque no tienen impacto estadístico en el resultado final.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6782e43b-cda4-43f3-998c-f3f535111a77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
