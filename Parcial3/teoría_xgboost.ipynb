{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "924a512f-db15-4b1b-a424-741aedfd8b9b",
   "metadata": {},
   "source": [
    "# XGBoost ‚Äì Explicaci√≥n Matem√°tica Paso a Paso\n",
    "\n",
    "XGBoost es una versi√≥n optimizada y regularizada del algoritmo de Gradient Boosting. A diferencia del boosting cl√°sico, utiliza **expansi√≥n de Taylor de segundo orden** y una funci√≥n objetivo regularizada para mejorar la eficiencia y evitar overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Funci√≥n objetivo de XGBoost\n",
    "\n",
    "## XGBoost como modelo aditivo\n",
    "\n",
    "XGBoost es un modelo **aditivo de √°rboles**, lo que significa que construye el modelo final sumando √°rboles uno a uno:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i^{(t)} = \\hat{y}_i^{(t-1)} + f_t(x_i)\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $\\hat{y}_i^{(t)}$ es la predicci√≥n del ejemplo $i$ en la iteraci√≥n $t$\n",
    "- $f_t(x_i)$ es el nuevo √°rbol que se entrena en la iteraci√≥n $t$\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivo en cada iteraci√≥n\n",
    "\n",
    "En cada paso, el nuevo √°rbol $f_t$ busca **minimizar la contribuci√≥n marginal** a la funci√≥n de p√©rdida total. Es decir, tomamos la funci√≥n objetivo y la separamos en:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}^{(t)} =\n",
    "\\underbrace{\n",
    "\\sum_{i=1}^n l(y_i, \\hat{y}_i^{(t-1)}) + \\sum_{k=1}^{t-1} \\Omega(f_k)\n",
    "}_{\\text{Parte ya construida (constante en esta iteraci√≥n)}} +\n",
    "\\underbrace{\n",
    "\\sum_{i=1}^n \\left[ l(y_i, \\hat{y}_i^{(t-1)} + f_t(x_i)) - l(y_i, \\hat{y}_i^{(t-1)}) \\right] + \\Omega(f_t)\n",
    "}_{\\text{Lo que a√±ade el nuevo √°rbol $f_t$}}\n",
    "$$\n",
    "\n",
    "Esto enfatiza que:\n",
    "\n",
    "- Solo necesitamos **optimizar el segundo t√©rmino**, ya que el primero no cambia en esta iteraci√≥n.\n",
    "- El nuevo √°rbol $f_t$ se entrena para **mejorar la predicci√≥n actual** $\\hat{y}_i^{(t-1)}$ sumando una correcci√≥n.\n",
    "\n",
    "Sin segmentar: \n",
    "\n",
    "$$\n",
    "\\mathcal{L}^{(t)} =\n",
    "\\sum_{i=1}^n l(y_i, \\hat{y}_i^{(t-1)} + f_t(x_i)) + \\sum_{k=1}^{t} \\Omega(f_k)\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## ‚öôÔ∏è Componentes de la funci√≥n objetivo\n",
    "\n",
    "- $l(y_i, \\hat{y}_i)$: funci√≥n de p√©rdida (por ejemplo, log-loss o MSE)\n",
    "- $\\hat{y}_i^{(t)} = \\hat{y}_i^{(t-1)} + f_t(x_i)$: predicci√≥n en el paso $t$\n",
    "- $\\Omega(f_k)$: penalizaci√≥n por la complejidad del √°rbol $f_k$\n",
    "\n",
    "La regularizaci√≥n $\\Omega(f)$ se define como:\n",
    "\n",
    "$$\n",
    "\\Omega(f) = \\gamma T + \\frac{1}{2} \\lambda \\sum_{j=1}^{T} w_j^2\n",
    "$$\n",
    "\n",
    "- $T$: n√∫mero de hojas en el √°rbol\n",
    "- $w_j$: valor predicho por la hoja $j$\n",
    "- $\\gamma$: penalizaci√≥n por cada hoja (controla el crecimiento del √°rbol)\n",
    "- $\\lambda$: penalizaci√≥n L2 sobre los valores de las hojas (controla magnitudes extremas)\n",
    "\n",
    "\n",
    "---\n",
    "## 2. Expansi√≥n de Taylor\n",
    "\n",
    "### Recordatorio r√°pido\n",
    "\n",
    "Cuando una funci√≥n es complicada, podemos aproximarla cerca de un punto usando una **expansi√≥n de Taylor de segundo orden**:\n",
    "\n",
    "$$\n",
    "f(x) \\approx f(a) + f'(a)(x - a) + \\frac{1}{2} f''(a)(x - a)^2\n",
    "$$\n",
    "\n",
    "En particular, si centramos la expansi√≥n en $a = 0$ (como hace XGBoost), tenemos:\n",
    "\n",
    "$$\n",
    "f(x) \\approx f(0) + f'(0)x + \\frac{1}{2} f''(0)x^2\n",
    "$$\n",
    "\n",
    "Esto nos da una **aproximaci√≥n cuadr√°tica** que es m√°s informativa que una l√≠nea recta (como en el gradiente descendente cl√°sico), y a√∫n as√≠ es eficiente de optimizar.\n",
    "\n",
    "---\n",
    "\n",
    "### Aplicaci√≥n en XGBoost\n",
    "\n",
    "Para poder usar boosting con funciones de p√©rdida arbitrarias (como log-loss o MAE), XGBoost necesita una forma de **aproximar la p√©rdida** alrededor de las predicciones actuales $\\hat{y}_i^{(t-1)}$.\n",
    "\n",
    "Ah√≠ es donde entra la expansi√≥n de Taylor:\n",
    "\n",
    "$$\n",
    "l(y_i, \\hat{y}_i^{(t)}) = l(y_i, \\hat{y}_i^{(t-1)} + f_t(x_i)) \\approx l(y_i, \\hat{y}_i^{(t-1)}) + g_i f_t(x_i) + \\frac{1}{2} h_i f_t(x_i)^2\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $g_i = \\left.\\frac{\\partial l}{\\partial \\hat{y}_i}\\right|_{\\hat{y}_i^{(t-1)}}$: gradiente\n",
    "- $h_i = \\left.\\frac{\\partial^2 l}{\\partial \\hat{y}_i^2}\\right|_{\\hat{y}_i^{(t-1)}}$: hessiano\n",
    "- $f_t(x_i)$ es **la predicci√≥n del nuevo √°rbol**, es decir, la correcci√≥n que se le va a sumar a la predicci√≥n actual\n",
    "\n",
    "El primer t√©rmino $l(y_i, \\hat{y}_i^{(t-1)})$ se puede ignorar en esta iteraci√≥n, ya que es constante.\n",
    "\n",
    "---\n",
    "\n",
    "#### üß† Conexi√≥n clave: ¬øpor qu√© aparece $f_t(x_i)$?\n",
    "\n",
    "Recuerda que en la expansi√≥n de Taylor:\n",
    "\n",
    "$$\n",
    "f(x) \\approx f(a) + f'(a)(x - a) + \\frac{1}{2} f''(a)(x - a)^2\n",
    "$$\n",
    "\n",
    "Si definimos:\n",
    "- $x = \\hat{y}_i^{(t)}$\n",
    "- $a = \\hat{y}_i^{(t-1)}$\n",
    "- Entonces: $x - a = \\hat{y}_i^{(t)} - \\hat{y}_i^{(t-1)} = f_t(x_i)$\n",
    "\n",
    "> ‚úÖ As√≠ que en XGBoost, **$f_t(x_i)$ es exactamente el $(x - a)$ de la expansi√≥n de Taylor**.\n",
    "\n",
    "---\n",
    "\n",
    "### Resultado\n",
    "\n",
    "La funci√≥n que efectivamente se optimiza en cada iteraci√≥n es:\n",
    "\n",
    "$$\n",
    "\\tilde{\\mathcal{L}}^{(t)} = \\sum_{i=1}^n \\left[ g_i f_t(x_i) + \\frac{1}{2} h_i f_t(x_i)^2 \\right] + \\Omega(f_t)\n",
    "$$\n",
    "\n",
    "Esto convierte la optimizaci√≥n en un problema **cuadr√°tico respecto a $f_t(x_i)$**, lo que permite construir el nuevo √°rbol de forma eficiente.\n",
    "\n",
    "---\n",
    "\n",
    "## ¬øPor qu√© usamos Taylor?\n",
    "\n",
    "La p√©rdida original puede ser arbitraria (por ejemplo, log-loss o MAE), y no tiene una forma cerrada f√°cil de minimizar al agregar un nuevo √°rbol.  \n",
    "Por eso, usamos una **expansi√≥n de segundo orden** para aproximarla por una funci√≥n cuadr√°tica, que s√≠ podemos minimizar f√°cilmente al construir un √°rbol hoja por hoja.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. √Årboles como funciones pieza por pieza\n",
    "\n",
    "Cada nuevo √°rbol $f_t$ asigna un valor constante $w_j$ a cada regi√≥n $R_j$ (una hoja). Entonces:\n",
    "\n",
    "$$\n",
    "f_t(x_i) = w_j \\quad \\text{si } x_i \\in R_j\n",
    "$$\n",
    "\n",
    "Sustituyendo esto en la funci√≥n objetivo aproximada:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}^{(t)} \\approx \\sum_{j=1}^{T} \\left[\n",
    "\\sum_{i \\in R_j} g_i w_j + \\frac{1}{2} \\sum_{i \\in R_j} h_i w_j^2\n",
    "\\right] + \\gamma T + \\frac{1}{2} \\lambda \\sum_{j=1}^{T} w_j^2\n",
    "$$\n",
    "\n",
    "Agrupando:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}^{(t)} \\approx \\sum_{j=1}^{T} \\left[\n",
    "G_j w_j + \\frac{1}{2} (H_j + \\lambda) w_j^2\n",
    "\\right] + \\gamma T\n",
    "$$\n",
    "\n",
    "Con:\n",
    "- $G_j = \\sum_{i \\in R_j} g_i$\n",
    "- $H_j = \\sum_{i \\in R_j} h_i$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Output Value por hoja\n",
    "\n",
    "Minimizamos el t√©rmino por hoja respecto a $w_j$:\n",
    "\n",
    "$$\n",
    "\\frac{d}{dw_j} \\left( G_j w_j + \\frac{1}{2} (H_j + \\lambda) w_j^2 \\right) = 0\n",
    "$$\n",
    "\n",
    "Soluci√≥n:\n",
    "\n",
    "$$\n",
    "\\textbf{Output value} = w_j^* = -\\frac{G_j}{H_j + \\lambda}\n",
    "$$\n",
    "\n",
    "Nota: esta soluci√≥n es equivalente al paso de Newton-Raphson aplicado a cada hoja, ya que minimizamos una aproximaci√≥n cuadr√°tica local de la p√©rdida.\n",
    "\n",
    "\n",
    "---\n",
    "## 5. Similarity Score (calidad de una hoja)\n",
    "\n",
    "No es una loss en el sentido habitual, pero s√≠ es proporcional a la p√©rdida que se reduce si mantienes esa hoja y usas el output value √≥ptimo.\n",
    "\n",
    "Recordemos que la funci√≥n de p√©rdida regularizada en una hoja $R_j$ es:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_j(w_j) = G_j w_j + \\frac{1}{2} (H_j + \\lambda) w_j^2\n",
    "$$\n",
    "\n",
    "- $G_j = \\sum_{i \\in R_j} g_i$: suma de gradientes en la hoja\n",
    "- $H_j = \\sum_{i \\in R_j} h_i$: suma de hessianos\n",
    "- $\\lambda$: t√©rmino de regularizaci√≥n L2\n",
    "\n",
    "\n",
    "\n",
    "### Evaluamos cu√°nto mejora la p√©rdida\n",
    "\n",
    "Sustituimos el valor √≥ptimo de nuevo en la funci√≥n de p√©rdida para ver **cu√°nto mejora**:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_j(w_j^*) = G_j w_j^* + \\frac{1}{2}(H_j + \\lambda)(w_j^*)^2\n",
    "$$\n",
    "\n",
    "Sustituyendo:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_j(w_j^*) =\n",
    "G_j \\left(-\\frac{G_j}{H_j + \\lambda} \\right) +\n",
    "\\frac{1}{2}(H_j + \\lambda) \\left( \\frac{G_j^2}{(H_j + \\lambda)^2} \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= -\\frac{G_j^2}{H_j + \\lambda} + \\frac{1}{2} \\cdot \\frac{G_j^2}{H_j + \\lambda}\n",
    "= -\\frac{1}{2} \\cdot \\frac{G_j^2}{H_j + \\lambda}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Resultado\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\text{Similarity Score} = \\frac{G_j^2}{H_j + \\lambda}\n",
    "}\n",
    "$$\n",
    "\n",
    "Este valor representa el **doble de la reducci√≥n en la p√©rdida** que se logra usando esa hoja con su output value √≥ptimo.\n",
    "\n",
    "- Es √∫til para comparar qu√© tan ‚Äúbuena‚Äù es una hoja antes de hacer un split.\n",
    "- Cuanto mayor sea, m√°s √∫til es mantener esa hoja o hacer un split basado en ella.\n",
    "\n",
    "üí° Nota: la funci√≥n de p√©rdida es negativa porque estamos midiendo una reducci√≥n (mejora). El **similarity score** se define como el valor positivo que indica esta ganancia potencial.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## 6. Gain (ganancia de un split)\n",
    "\n",
    "Para saber si vale la pena dividir una hoja en dos, se calcula la **ganancia** del split:\n",
    "\n",
    "\n",
    "Cuando se eval√∫a un posible split, se calcula la **ganancia esperada**:\n",
    "\n",
    "$$\n",
    "\\text{Gain} = \\frac{1}{2} \\left( \\text{Similarity}_\\text{izq} + \\text{Similarity}_\\text{der} - \\text{Similarity}_\\text{padre} \\right) - \\gamma\n",
    "$$\n",
    "\n",
    "\n",
    "Si el gain es positivo, se realiza el split, $\\gamma$ es un hiperpar√°metro\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Predicci√≥n final\n",
    "\n",
    "La predicci√≥n final se obtiene sumando todos los √°rboles:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = F_0(x_i) + \\sum_{t=1}^{M} f_t(x_i)\n",
    "$$\n",
    "\n",
    "Y si es clasificaci√≥n, se aplica la funci√≥n sigmoide para convertir a probabilidad:\n",
    "\n",
    "$$\n",
    "p_i = \\frac{1}{1 + e^{-\\hat{y}_i}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ En resumen\n",
    "\n",
    "| Concepto            | F√≥rmula                                                       | Interpretaci√≥n                                |\n",
    "|---------------------|----------------------------------------------------------------|------------------------------------------------|\n",
    "| Output value        | $w_j = -\\frac{G_j}{H_j + \\lambda}$                         | Valor √≥ptimo que predice una hoja             |\n",
    "| Similarity score    | $\\frac{G_j^2}{H_j + \\lambda}$                              | Calidad de una hoja                           |\n",
    "| Gain (split)        | Ver f√≥rmula anterior                                           | Reducci√≥n esperada en la p√©rdida si se divide |\n",
    "\n",
    "---\n",
    "\n",
    "## Derivadas para diferentes funciones de p√©rdida\n",
    "\n",
    "A continuaci√≥n se muestran las f√≥rmulas del **gradiente** y el **hessiano** seg√∫n el tipo de problema:\n",
    "\n",
    "| Tipo de problema       | Funci√≥n de p√©rdida                                 | Gradiente $g_i$                  | Hessiano $h_i$                       |\n",
    "|------------------------|----------------------------------------------------|----------------------------------|--------------------------------------|\n",
    "| Regresi√≥n (MSE)        | $\\mathcal{L}(y_i, \\hat{y}_i) = \\frac{1}{2}(y_i - \\hat{y}_i)^2$ | $g_i = \\hat{y}_i - y_i$          | $h_i = 1$                            |\n",
    "| Clasificaci√≥n binaria  | $\\mathcal{L}(y_i, \\hat{y}_i) = -[y_i \\log(p_i) + (1 - y_i)\\log(1 - p_i)]$ con $p_i = \\sigma(\\hat{y}_i)$ | $g_i = p_i - y_i$                | $h_i = p_i(1 - p_i)$                 |\n",
    "\n",
    "- En clasificaci√≥n binaria, $\\hat{y}_i$ es el **logit** y $p_i = \\frac{1}{1 + e^{-\\hat{y}_i}}$\n",
    "- En regresi√≥n, $\\hat{y}_i$ es la predicci√≥n directa del modelo\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eba0079-a955-4499-9c1d-9c301d804a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc8975d-ba91-45e0-846b-a55d0cf0d8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4640fb78-74f4-4614-93cd-8ad644cb82d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6add6369-5075-4fe1-87da-7c1f6f544a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
