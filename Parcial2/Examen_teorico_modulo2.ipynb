{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58182883-edf4-410e-9fb5-3cc408d49dfb",
   "metadata": {},
   "source": [
    "# Examen modulo 2\n",
    "\n",
    "Diego Lozoya Morales | 745345\n",
    "\n",
    "## **Sección 1: Regresión Logística** (30 puntos)  \n",
    "\n",
    "1. **(10 pts)** Explica la diferencia entre la regresión logística **lineal** y la **polinomial**. ¿En qué casos es recomendable usar la versión polinomial?  \n",
    "\n",
    "La regresión logistica polinomial funciona para discriminar a las clases de manera más sencilla y directa (lineal), ya que asume que la relación entre las variables es lineal. Por otro lado la polinomial no asume esta relación entre variables, por lo que capta distintos tipos de tendencias. Justo es en estos cuasos cuando es recomendable utilizar a la versión polinomial, frente a la lineal, ya que se espera que haya una relación/patrón no tan directo entre las variables. El problema de estos modelo es su elevado costo computacional, frente alos modelos lineales, por lo que el credor del modelo deberá decidir si vale la pena aceptar ese costo a cambio de un mejor ajuste (poder predictivo).\n",
    "\n",
    "2. **(10 pts)** Explica como mediante decenso en gradiente y maxima verosimilitud creamos una regresión lógisitca  \n",
    "\n",
    "En primer lugar se sigue el proceso de máxima verosimilitud, en donde se supone que se sigue una distribución de bernoulli, por lo que la forma de verosimilitud es:\n",
    "\n",
    "$$L(\\theta) = \\prod_{i=1}^{m} p(y_i | X_i; \\theta) = \\prod_{i=1}^{m} \\left[ \\sigma(\\theta^T X_i) \\right]^{y_i} \\cdot \\left[ 1 - \\sigma(\\theta^T X_i) \\right]^{(1 - y_i)}$$\n",
    "\n",
    "Este proceso es muy complicado de resolver por lo que se utilizan logaritmos. Al tomar el logaritmo de la verosimilitud se puede cambiar la multiplicatoria por sumatoria, por propiedades de los logaritmos:\n",
    "\n",
    "$$\\log L(\\theta) = \\sum_{i=1}^{m} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right]$$\n",
    "\n",
    "Maximizamos la log-verosimilitud para estimar $\\theta$. \n",
    "\n",
    "$$J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right]$$\n",
    "\n",
    "Dado esta forma no lineal no existe solución analítica (cerrada) para el problema, por lo que se utilizan cálculos computaciones con el método de decenso en gradiente para que estos coeficientes logren converger iterativamente.\n",
    "\n",
    "3. **(10 pts)** Explica el concepto de **odds** y **log-odds** en regresión logística. ¿Por qué la regresión logística predice el **log-odds** en lugar de la probabilidad directamente? Justifica esto   \n",
    "\n",
    "Las odds son la razón de éxito frente al fracaso en donde se calculan con la fórmmula:\n",
    "\n",
    "$$\\text{odds} = \\frac{p}{1-p}$$\n",
    "\n",
    "Ya que este crecimiento es exponencial, se aplica logaritmo, de modo que se linealice este comportamiento.\n",
    "\n",
    "$$log \\text{ odds} = log (\\frac{p}{1-p})$$\n",
    "\n",
    "Una vez que se tienen los coeficientes de la regresión logística, con ayuda del sigmoide se calcula la combinación lineal de los coeficientes con las características (X), obteniendo el valor de z \n",
    "\n",
    "$$z=\\Theta ^T X$$\n",
    "\n",
    "Con esto se ultiliza la fórmula\n",
    "\n",
    "$$p= \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "donde p es la probabilidad de que el modelo clasifique como 1. Si la probabilidad es menor a 0.5 se clasifica como 0 y si es mayor a 0.5 de clasiifica como 1.\n",
    "\n",
    "Se utilizan a los log odds, en lugar de las probabilidad como tal, por su forma exponencial. Al aplicar logaritmo, es una forma de linealizar los datos.\n",
    "\n",
    "\n",
    "## **Sección 2: Área Bajo la Curva (AUC)** (20 puntos)  \n",
    "\n",
    "7. **(5 pts)** Define la **curva ROC** y el AUC. ¿Qué tiene de especial\n",
    "\n",
    "La curva ROC es la manera gráfica de representar el potencial de discriminación de un modelo frente a distintos umbrales de decisión.\n",
    "\n",
    "El AUC es una métrica de desempeo que se representa graficamente como el área bajo la curva ROC. Si se toman dos personas al azar, una clasificada con 1 y una con 0, el AUC es la probabilidad de que la persona clasificada con 1 tenga una mayor probabilidad de predicción con el modelo, a la persona clasificada con 0.\n",
    "\n",
    "8. **(5 pts)** Cuando hacemos una curva ROC, siempre ponemos una diagonal, explica que es esa diagonal  \n",
    "\n",
    "La diagonal representa un modelo cuya capacidad de discriminación es aleatoria (50%-50%). Ya que es igualmente probable que clasifique a cualquiera de las catogorías su trayecroria es recta sim importar el umbral.\n",
    "\n",
    "9.  **(5 pts)** Un modelo tiene un **AUC de 0.85**. Explica qué significa esto en términos de su capacidad de clasificación.  \n",
    "\n",
    "Un AUC de 0.85, generalmente se ve como un buen modelo. En términos de su capacidad de clasificación significa, que si se selecciona una persona al azar, hay un 85% de probabilidad de que el modelo clasifique correctamente a una persona como 1, en lugar de 0.\n",
    "\n",
    "10. **(5 pts)** Un modelo tiene accuracy de 99% pero AUC de 0.5%, ¿Cómo es que esto podría suceder?\n",
    "\n",
    "Esto podría suceder por la diferencia de cantidad de datos que se tienen entre clases en un dataset. Un accuracy de 99% significa que l modelo clasificó el 99% de los datos correctamente, sin embargo, el AUC de 50% sería como la diagonal del ROC, un modelo con clasificación aleatoria 50-50. Ya que el modelo es entrenado a predecir siempre la clase mayoritaria una desproporción de los datos en el dataset, haría que aunque siempre clasifique bien el modelo, no sepa realmente como clasificar a los datos.\n",
    "\n",
    "## **Sección 3: Análisis del Discriminante Lineal (LDA)** (10 puntos)  \n",
    "\n",
    "11. **(10 pts)** ¿Qué es el análisis del discriminante lineal? ¿En que casos lo usarías? (gausiano)\n",
    "\n",
    "Suponiedo que la distribución de cada clase en el modelo es normal multivariada, su forma es:\n",
    "\n",
    "$$P(\\mathbf{x} | y = k) = \\frac{1}{(2\\pi)^{n/2}|\\Sigma_k|^{1/2}} e^{\\left(-\\frac{1}{2}(\\mathbf{x} - \\mu_k)^T \\Sigma_k^{-1} (\\mathbf{x} - \\mu_k)\\right)}$$\n",
    "\n",
    "Con base en esto, en primer lugar se calcula la proporción de datos pertenecientes por clase, para después calcular la probabilidad de pertenecia de un nuevo dato a cada clase con el teorema de Bayes. El modelo discrimina con la clase cuya probabilidad sea más alta, con la fórmula:\n",
    "\n",
    "$$P(y = k | \\mathbf{x}) = \\frac{P(\\mathbf{x} | y = k) P(y = k)}{P(\\mathbf{x})}$$\n",
    "\n",
    "El LDA es utilizado cuando se quiere separar en grupos a una población. Como su nombre lo indica es para discriminar los datos y asignarlos a un nuevo grupo, en donde tienen cosas en común.\n",
    "\n",
    "## Sección 4: Cross validation  (10 puntos)  \n",
    "\n",
    "12. **(10 pts)** ¿Qué es grid search? ¿qué es random search? Explica las diferencias y cuando usarías cada uno \n",
    "\n",
    "El grid search es un método en el que se prueban diferentes métricas (parámetros) para la implementación de un modelo. Muchas veces cuando se quiere crear un modelo, el mejor resultado depende de prueba y error, por lo que es complicado encontrar el mejor resultado. Con el Grid search se introducen varias al mismo tiempo, y el grid search ace la prueba de todas las combinaciones de parámetros dados, devolviendo el mejor resultado, según una métrica de desempeño. El random search es similar al grid, sin embargo este no prueba todas las combinaciones posibles, sino que se manera aleatoria selleciona algunas combinaciones y arroja el resultado. \n",
    "\n",
    "Por estas diferencias sería adecuado utilizar el random search cuando se esta creando un modelo en sus etapas iniciales, para comenzar a probar de manera más rápida (ya que no utiliza todas las combinaciones). Cuando ya se tenga el modelo final, se recomendaría cambiar a un grid search, para obtener un modelo con mejor ajuste. Se recomienda esta distinición que el grid search es mucho más caro en términos computacionales, por la cantidad de combinación de parámtros que prueba.\n",
    "\n",
    "## **Sección 5: Redes Neuronales y Perceptrón Multicapa** (20 puntos)  \n",
    "\n",
    "13. **(5 pts)** Explica que es una red neuronal, que hace, como funciona, etc.\n",
    "\n",
    "Una red neuronal se divide en 2 grandes pasos, forward propagation y backpropagation.\n",
    "- **Forward propagation**:\n",
    "     Hay una entrada de datos, seguido de n capas. En cada una de las capas los datos son multiplicados por unos pesos (combinación lineal) y son transformados con base en una función de activación, la cual puede ser diferente o igual a la del resto de capas. Finalmente el modelo arroga un único resultado, el cuál es la combinación lineal de cada una de la capas. \n",
    "     \n",
    "- **Backpropagation**:\n",
    "     Ya que el resultado del forward propagation es bastante malo, se distribuye el error calculado por neurona, a todo el resto de capas. La forma de distribuir este error es modificando los pesos de la combinación lineal de modo que se mejora el resultado.  \n",
    " \n",
    "14. **(5 pts)** ¿Cuál es el propósito de la **backpropagation** en el entrenamiento de redes neuronales? \n",
    "\n",
    "Su propósito es redistribuir el error que se calcula en el modelo, de modo que se pueda maximizar la métrica de medición del modelo, en este caso $R^2$. La forma en la que redistribuye este error es cambiando los pesos que ultiliza para la combinación lineal por capa.\n",
    "\n",
    "15. **(5 pts)** A grandes rasgos, explica como obtenemos los coeficientes de una red neuronal  \n",
    "\n",
    "Estos coeficiente se obtienen iterando un proceso que está compuesto por forward propagation y backpropagation. Realiza un modelo con la combinación lineal de los pesos de los coeficientes (forward propagation) y después actualiza el error modificando estos pesos (backpropagation). La forma en la que va actualizando estos pesos es con decenso en gradiente, hasta converger en un óptimo.\n",
    "\n",
    "## **Sección 6: Softmax** (10 puntos)  \n",
    "16. **(5 pts)** Explica que es softmax, para que sirve y como se calcula\n",
    "\n",
    "El softmax se utiliza de manera similar a la regresión logísica, sin embargo, este clasifica en más de dos clases (0 y 1) modelando las probabilidad para cada una de las clases.\n",
    "\n",
    "La función Softmax convierte las salidas de la función lineal en probabilidades:\n",
    "\n",
    "$$P(y = k | \\mathbf{x}) = \\frac{e^{\\mathbf{w}_k \\cdot \\mathbf{x} + b_k}}{\\sum_{j=1}^{K} e^{\\mathbf{w}_j \\cdot \\mathbf{x} + b_j}}$$\n",
    "\n",
    "**Ejemplo Numérico**\n",
    "\n",
    "Si tenemos 3 clases y logits calculados como:\n",
    "\n",
    "$$z_1 = 2, \\quad z_2 = 1, \\quad z_3 = -1$$\n",
    "\n",
    "Aplicamos Softmax:\n",
    "\n",
    "$$P(y=1) = \\frac{e^2}{e^2 + e^1 + e^{-1}} = 0.72$$\n",
    "\n",
    "$$P(y=2) = \\frac{e^1}{e^2 + e^1 + e^{-1}} = 0.26$$\n",
    "\n",
    "$$P(y=3) = \\frac{e^{-1}}{e^2 + e^1 + e^{-1}} = 0.04$$\n",
    "\n",
    "Esto indica que la clase 1 es la más probable, por lo que el modelo la clasificará como 1.\n",
    "\n",
    "## **Puntaje Total: 100 puntos**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1178f20-e11d-4c3b-8966-83f05be61004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
